import streamlit as st
import os
import re
import time
# import threading # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì œê±°
import queue
import random
import hashlib
import logging
from datetime import datetime, timezone, timedelta
from urllib.parse import quote
import requests
import html
import json
import pandas as pd
import io

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
from twocaptcha import TwoCaptcha
from PIL import Image
import base64

# APP_DATA_FILE = "app_data.json" # ë¡œì»¬ íŒŒì¼ ì €ì¥ ê¸°ëŠ¥ ì‚­ì œ

# --- Page Config ---
st.set_page_config(
    page_title="Playboard Scraper",
    page_icon="ğŸ“Š",
    layout="wide"
)

# --- Data Persistence Functions (ì‚­ì œ) ---
# save_app_data, load_app_data í•¨ìˆ˜ë¥¼ ëª¨ë‘ ì‚­ì œí•©ë‹ˆë‹¤.

# --- Session State Initialization ---
def initialize_session_state():
    """Initializes all the necessary variables in streamlit's session state for each user."""
    # persistent_data = load_app_data() # ë¡œì»¬ íŒŒì¼ ë¡œë”© ë¡œì§ ì‚­ì œ
    
    if 'driver' not in st.session_state:
        st.session_state.driver = None
    if 'login_status' not in st.session_state:
        st.session_state.login_status = "Not logged in"
    if 'log_messages' not in st.session_state:
        st.session_state.log_messages = []
    if 'scraped_data' not in st.session_state:
        st.session_state.scraped_data = pd.DataFrame()
    if 'is_scraping' not in st.session_state:
        st.session_state.is_scraping = False
    if 'progress' not in st.session_state:
        st.session_state.progress = 0
    if 'subscriber_filters' not in st.session_state:
        st.session_state.subscriber_filters = {
            "0K~100K": {"0~1K": False, "1K~5K": False, "5K~10K": False, "10K~50K": False, "50K~100K": False},
            "100K~1M": {"100K~500K": False, "500K~1M": False},
            "1M~5M": {"1M~1.5M": False, "1.5M~2M": False, "2M~2.5M": False, "2.5M~3M": False, "3M~3.5M": False, "3.5M~4M": False, "4M~4.5M": False, "4.5M~5M": False},
            "5M~10M": {"5M~5.5M": False, "5.5M~6M": False, "6M~6.5M": False, "6.5M~7M": False, "7M~7.5M": False, "7.5M~8M": False, "8M~8.5M": False, "8.5M~9M": False, "9M~9.5M": False, "9.5M~10M": False},
            "10M+": {"10M+": False}
        }
        st.session_state.filter_ranges = {
            "0~1K": (0, 1000), "1K~5K": (1000, 5000), "5K~10K": (5000, 10000), "10K~50K": (10000, 50000), "50K~100K": (50000, 100000),
            "100K~500K": (100000, 500000), "500K~1M": (500000, 1000000),
            "1M~1.5M": (1000000, 1500000), "1.5M~2M": (1500000, 2000000), "2M~2.5M": (2000000, 2500000), "2.5M~3M": (2500000, 3000000), "3M~3.5M": (3000000, 3500000), "3.5M~4M": (3500000, 4000000), "4M~4.5M": (4000000, 4500000), "4.5M~5M": (4500000, 5000000),
            "5M~10M": {"5M~5.5M": (5000000, 5500000), "5.5M~6M": (5500000, 6000000), "6M~6.5M": (6000000, 6500000), "6.5M~7M": (6500000, 7000000), "7M~7.5M": (7000000, 7500000), "7.5M~8M": (7500000, 8000000), "8M~8.5M": (8000000, 8500000), "8.5M~9M": (8500000, 9000000), "9M~9.5M": (9000000, 9500000), "9.5M~10M": (9500000, 10000000)},
            "10M+": {"10M+": (10000000, float('inf'))}
        }
    if 'use_custom_filter' not in st.session_state:
        st.session_state.use_custom_filter = False
    if 'custom_min' not in st.session_state:
        st.session_state.custom_min = -1
    if 'custom_max' not in st.session_state:
        st.session_state.custom_max = -1
    if 'is_filter_applied' not in st.session_state:
        st.session_state.is_filter_applied = False
    
    if 'crawl_settings' not in st.session_state:
        st.session_state.crawl_settings = {
            "max_items": 5000, "dates": [], "country_code": "south-korea", "country_name": "í•œêµ­"
        }
    
    if 'shopping_cart' not in st.session_state:
        # cart_data = persistent_data.get('shopping_cart', []) # ì‚­ì œ
        st.session_state.shopping_cart = pd.DataFrame()

    if 'custom_groups' not in st.session_state:
        # groups_data = persistent_data.get('custom_groups', {}) # ì‚­ì œ
        st.session_state.custom_groups = {}

    if '2captcha_api_key' not in st.session_state:
        # st.session_state['2captcha_api_key'] = persistent_data.get('2captcha_api_key', '') # ì‚­ì œ
        st.session_state['2captcha_api_key'] = ''

initialize_session_state()

# --- Logging and Progress ---
def log(message):
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.log_messages.append(f"[{timestamp}] {message}")
    print(f"[LOG] {message}")

def update_progress(value):
    st.session_state.progress = value

# --- Helper Functions ---
def extract_video_id_from_thumbnail(thumb_url):
    if "ytimg.com/vi/" in thumb_url:
        parts = thumb_url.split("ytimg.com/vi/")
        if len(parts) > 1:
            video_id = parts[1].split("/")[0].split("_")[0]
            if 8 <= len(video_id) <= 15:
                return video_id
    return None

def extract_video_id_from_href(href):
    if "/video/" in href:
        parts = href.split("/video/")
        if len(parts) > 1:
            video_id = parts[1].split("?")[0].split("&")[0]
            if 8 <= len(video_id) <= 15:
                return video_id
    return None

def parse_subscriber_count(count_text):
    if not count_text or count_text == "êµ¬ë…ì ì •ë³´ ì—†ìŒ":
        return count_text
    return re.sub(r'[^0-9,]', '', count_text)

def convert_subscriber_count_to_int(count_text):
    if not count_text or count_text == "êµ¬ë…ì ì •ë³´ ì—†ìŒ":
        return -1
    try:
        return int(count_text.replace(',', ''))
    except (ValueError, TypeError):
        return -1

def parse_views_to_int(view_text):
    """Converts view counts with suffixes (K, M, B) to integers."""
    view_text = str(view_text).strip().upper()
    view_text = view_text.replace(',', '')
    if 'K' in view_text:
        return int(float(view_text.replace('K', '')) * 1000)
    if 'M' in view_text:
        return int(float(view_text.replace('M', '')) * 1000000)
    if 'B' in view_text:
        return int(float(view_text.replace('B', '')) * 1000000000)
    try:
        return int(view_text)
    except (ValueError, TypeError):
        return 0

def generate_hash(title, channel):
    normalized_title = re.sub(r'[^\w]', '', title.lower())
    normalized_channel = channel.lower()
    combined = f"{normalized_title}|{normalized_channel}"
    return hashlib.md5(combined.encode()).hexdigest()

@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

def parse_dates(date_str):
    dates = []
    parts = date_str.replace(" ", "").split(',')
    for part in parts:
        if '-' in part:
            try:
                start_s, end_s = part.split('-')
                start_d = datetime.strptime(start_s, '%Y%m%d')
                end_d = datetime.strptime(end_s, '%Y%m%d')
                delta = end_d - start_d
                for i in range(delta.days + 1):
                    day = start_d + timedelta(days=i)
                    dates.append(day.strftime('%Y%m%d'))
            except Exception as e:
                log(f"ë‚ ì§œ ë²”ìœ„ íŒŒì‹± ì˜¤ë¥˜ '{part}': {e}")
        elif len(part) == 8 and part.isdigit():
            dates.append(part)
    return sorted(list(set(dates)))

def convert_df_to_pdf(df):
    try:
        plt.rcParams['font.family'] = 'Malgun Gothic'
        plt.rcParams['axes.unicode_minus'] = False 
    except Exception as e:
        log("âš ï¸ 'Malgun Gothic' í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PDFì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        log("Windows ì‚¬ìš©ìê°€ ì•„ë‹Œ ê²½ìš°, ì‹œìŠ¤í…œì— ë§ëŠ” í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì¹˜í•˜ê³  ì½”ë“œë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.axis('tight')
    ax.axis('off')
    
    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center', colWidths=[0.1, 0.3, 0.1, 0.15, 0.1, 0.15, 0.1, 0.2])
    table.auto_set_font_size(False)
    table.set_fontsize(8)
    table.scale(1.2, 1.2)

    pdf_buffer = io.BytesIO()
    with PdfPages(pdf_buffer) as pdf:
        pdf.savefig(fig, bbox_inches='tight')
    
    return pdf_buffer.getvalue()


# --- Filter Logic ---
def should_include_subscriber(subscriber_count):
    if not st.session_state.is_filter_applied:
        return True
    if subscriber_count == -1:
        return False

    any_filter_selected = any(
        st.session_state.subscriber_filters[cat][range_name]
        for cat in st.session_state.subscriber_filters
        for range_name in st.session_state.subscriber_filters[cat]
    )

    if not any_filter_selected and not st.session_state.use_custom_filter:
        return True

    for cat in st.session_state.subscriber_filters:
        for range_name, is_selected in st.session_state.subscriber_filters[cat].items():
            if is_selected:
                min_val, max_val = st.session_state.filter_ranges[range_name]
                if min_val <= subscriber_count < max_val:
                    return True
    
    if st.session_state.use_custom_filter:
        min_val, max_val = st.session_state.custom_min, st.session_state.custom_max
        if min_val >= 0 and max_val < 0:
            return subscriber_count >= min_val
        elif min_val < 0 and max_val >= 0:
            return subscriber_count <= max_val
        elif min_val >= 0 and max_val >= 0:
            return min_val <= subscriber_count <= max_val
            
    return False

# --- Selenium/Scraping Logic ---
def init_driver():
    options = Options()
    # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë“œì— ë”°ë¼ í—¤ë“œë¦¬ìŠ¤ ì˜µì…˜ì„ ì¡°ê±´ë¶€ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
    if st.session_state.get("run_headless", True):
        log("INFO: í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        options.add_argument("--headless")
        options.add_argument("--window-size=1920,1080")
    else:
        log("INFO: ì¼ë°˜ ëª¨ë“œ(í—¤ë“œë¦¬ìŠ¤ ì•„ë‹˜)ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. ìº¡ì±  ë°œìƒ ì‹œ ì§ì ‘ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    
    try:
        log("INFO: WebDriverë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
        driver = webdriver.Chrome(options=options)
        driver.set_page_load_timeout(30)
        return driver
    except Exception as e:
        log(f"âŒ WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.error(f"WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. ë°°í¬ í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None

def do_login(email, password):
    if st.session_state.driver is None:
        st.session_state.driver = init_driver()
        if st.session_state.driver is None:
            return

    driver = st.session_state.driver
    log("ğŸŒ ì‚¬ì´íŠ¸ ì ‘ì† ì¤‘...")
    try:
        driver.get("https://playboard.co")
        wait = WebDriverWait(driver, 15)
        
        login_link = wait.until(EC.element_to_be_clickable((By.XPATH, "//a[text()='ë¡œê·¸ì¸']")))
        login_link.click()

        email_input = wait.until(EC.presence_of_element_located((By.XPATH, "//input[@name='email']")))
        password_input = wait.until(EC.presence_of_element_located((By.XPATH, "//input[@name='password']")))
        email_input.send_keys(email)
        password_input.send_keys(password)

        login_button = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[@type='submit' and .//span[text()='ë¡œê·¸ì¸']]")))
        login_button.click()

        wait.until(EC.invisibility_of_element_located((By.XPATH, "//input[@name='email']")))
        st.session_state.login_status = "âœ… ë¡œê·¸ì¸ ì„±ê³µ!"
        log("âœ… ë¡œê·¸ì¸ ì„±ê³µ!")
    except Exception as e:
        st.session_state.login_status = f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}"
        log(st.session_state.login_status)
        if st.session_state.driver:
            st.session_state.driver.quit()
            st.session_state.driver = None

def detect_and_handle_captcha(driver):
    try:
        # 1. ë©”ì¸ í”„ë ˆì„ì—ì„œ 'reCAPTCHA' iframe ì°¾ê¸°
        recaptcha_iframe = driver.find_elements(By.CSS_SELECTOR, "iframe[title='reCAPTCHA']")
        if not recaptcha_iframe:
            return None # ìº¡ì±  ì—†ìŒ

        log("INFO: 'ë¡œë´‡ì´ ì•„ë‹™ë‹ˆë‹¤' ìº¡ì±  iframe ë°œê²¬.")
        driver.switch_to.frame(recaptcha_iframe[0])
        
        # 2. 'ë¡œë´‡ì´ ì•„ë‹™ë‹ˆë‹¤' ì²´í¬ë°•ìŠ¤ í´ë¦­
        checkbox = driver.find_elements(By.ID, "recaptcha-anchor")
        if checkbox:
            checkbox[0].click()
            log("INFO: 'ë¡œë´‡ì´ ì•„ë‹™ë‹ˆë‹¤' ì²´í¬ë°•ìŠ¤ë¥¼ í´ë¦­í–ˆìŠµë‹ˆë‹¤.")
            time.sleep(3) # ì´ë¯¸ì§€ ì±Œë¦°ì§€ê°€ ë¡œë“œë  ì‹œê°„ì„ ì¤ë‹ˆë‹¤.
        
        # 3. ê¸°ë³¸ ì»¨í…ì¸ ë¡œ ëŒì•„ì™€ì„œ, ì´ë¯¸ì§€ ì±Œë¦°ì§€ iframe ì°¾ê¸°
        driver.switch_to.default_content()
        challenge_iframe = driver.find_elements(By.CSS_SELECTOR, "iframe[title*='ë³´ì•ˆë¬¸ì']")
        
        if not challenge_iframe:
            log("INFO: ì´ë¯¸ì§€ ì±Œë¦°ì§€ê°€ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìº¡ì± ê°€ í•´ê²°ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")
            return True

        if st.session_state.get('2captcha_api_key'):
            log("ğŸš¨ ì´ë¯¸ì§€ ì„ íƒí˜• ìº¡ì±  ë°œê²¬! 2Captchaë¡œ ìë™ í•´ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            driver.switch_to.frame(challenge_iframe[0])

            # 4. ì´ë¯¸ì§€ ìº¡ì²˜ ë° ì§ˆë¬¸ ì¶”ì¶œ
            img_element = driver.find_element(By.CSS_SELECTOR, "img.rc-image-tile-44")
            img_base64 = img_element.screenshot_as_base64
            
            instruction_element = driver.find_element(By.CSS_SELECTOR, ".rc-imageselect-instructions strong")
            instruction_text = instruction_element.text
            log(f"ìº¡ì±  ì§ˆë¬¸: '{instruction_text}'ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.")

            # 5. 2Captchaë¡œ í•´ê²° ìš”ì²­
            config = {'apiKey': st.session_state['2captcha_api_key']}
            solver = TwoCaptcha(**config)
            try:
                result = solver.recaptcha(
                    sitekey=driver.find_element(By.CSS_SELECTOR, ".g-recaptcha").get_attribute('data-sitekey'), # ì‚¬ì´íŠ¸ í‚¤ë¥¼ ë‹¤ì‹œ ê°€ì ¸ì˜´
                    url=driver.current_url,
                    method='image',
                    textinstructions=instruction_text,
                    body=f'base64:{img_base64}'
                )
                
                log("âœ… 2Captcha ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ. í† í°ì„ ì£¼ì…í•©ë‹ˆë‹¤.")
                recaptcha_response = result['code']
                
                driver.switch_to.default_content() # í† í° ì£¼ì…ì„ ìœ„í•´ ê¸°ë³¸ í”„ë ˆì„ìœ¼ë¡œ ëŒì•„ê°
                driver.execute_script(f"document.getElementById('g-recaptcha-response').innerHTML = '{recaptcha_response}';")
                log("INFO: ìº¡ì±  í•´ê²° í† í° ì£¼ì… ì™„ë£Œ.")
                
                # ì½œë°± í•¨ìˆ˜ ì‹¤í–‰ ë˜ëŠ” ì œì¶œ ì‹œë„
                driver.switch_to.frame(challenge_iframe[0]) # ë‹¤ì‹œ ì±Œë¦°ì§€ í”„ë ˆì„ìœ¼ë¡œ
                verify_button = driver.find_element(By.ID, "recaptcha-verify-button")
                verify_button.click()
                log("INFO: í™•ì¸ ë²„íŠ¼ í´ë¦­.")
                
                driver.switch_to.default_content()
                time.sleep(5)
                return True

            except Exception as e:
                log(f"âŒ 2Captcha ì´ë¯¸ì§€ í•´ê²° ì‹¤íŒ¨: {e}")
                driver.switch_to.default_content()
                return False
        
        elif challenge_iframe:
             log("ì´ë¯¸ì§€ ìº¡ì± ê°€ ê°ì§€ë˜ì—ˆìœ¼ë‚˜, 2Captcha API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¥¼ ë„ê³  ì§ì ‘ í•´ê²°í•´ì£¼ì„¸ìš”.")
             driver.switch_to.default_content()
             return False

    except Exception as e:
        log(f"âš ï¸ ìº¡ì±  ê°ì§€/ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        try:
            driver.switch_to.default_content()
        except: pass
    return False

def crawl(is_short, dates, country_code, country_name, max_items):
    st.session_state.is_scraping = True
    st.session_state.progress = 0

    try:
        all_collected_data = []
        processed_hashes = set()

        driver = st.session_state.driver
        if not driver:
            log("âŒ ë“œë¼ì´ë²„ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¡œê·¸ì¸ í•´ì£¼ì„¸ìš”.")
            return

        for a_date in dates:
            try:
                date_obj = datetime.strptime(a_date, '%Y%m%d')
                kst = timezone(timedelta(hours=9))
                date_obj = date_obj.replace(tzinfo=kst)
                key = int(date_obj.timestamp())
            except ValueError:
                log(f"âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {a_date}")
                continue

            log(f"ğŸ¯ {date_obj.strftime('%Y-%m-%d')} ë‚ ì§œ í¬ë¡¤ë§ ì‹œì‘ (ëª©í‘œ: {max_items}ê°œ)...")

            if is_short:
                url = f"https://playboard.co/chart/short/most-viewed-all-videos-in-{country_code}-daily?period={key}"
            else:
                url = f"https://playboard.co/chart/video/?period={key}"
            
            log(f"â¡ï¸ URLë¡œ ì´ë™ ì¤‘: {url}")
            
            try:
                driver.get(url)
                log("...í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
                WebDriverWait(driver, 45).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "a.title__label")))
                log("âœ… í˜ì´ì§€ ë¡œë”© ì™„ë£Œ.")
            except TimeoutException:
                log(f"âŒ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼: {url}")
                log("ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜, ì‚¬ì´íŠ¸ê°€ ë‹¤ìš´ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‚ ì§œë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                continue
            except Exception as e:
                log(f"âŒ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {e}")
                continue

            scroll_count = 0
            max_scrolls = (max_items // 20) + 15
            no_change_count = 0
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            prev_items_count = 0
            while True:
                current_items_on_page = len(driver.find_elements(By.CSS_SELECTOR, "a.title__label"))
                status_text.text(f"ìŠ¤í¬ë¡¤ {scroll_count}íšŒ, í˜ì´ì§€ í•­ëª©: {current_items_on_page}ê°œ")
                
                if current_items_on_page >= max_items:
                    log(f"âœ… ëª©í‘œ í•­ëª© ìˆ˜({max_items}) ì´ìƒì„ í˜ì´ì§€ì—ì„œ ì°¾ì•˜ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¡¤ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break

                if scroll_count >= max_scrolls:
                    log(f"âš ï¸ ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜({max_scrolls})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ê¹Œì§€ ì°¾ì€ í•­ëª©ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                    break
                
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                scroll_count += 1
                time.sleep(2.5) 
                
                new_items_on_page = len(driver.find_elements(By.CSS_SELECTOR, "a.title__label"))

                if new_items_on_page == prev_items_count:
                    no_change_count += 1
                    log(f"âš ï¸ ìŠ¤í¬ë¡¤ í›„ ìƒˆ í•­ëª©ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ({no_change_count}/3)")
                    if no_change_count >= 3:
                        log("ë” ì´ìƒ ìƒˆ í•­ëª©ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ìŠ¤í¬ë¡¤ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        if not detect_and_handle_captcha(driver):
                            break
                        else: 
                            no_change_count = 0
                else:
                    no_change_count = 0
                prev_items_count = new_items_on_page

            log("ğŸ” ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬ ì¤‘...")
            
            title_elements = driver.find_elements(By.CSS_SELECTOR, "a.title__label")
            view_elements = driver.find_elements(By.CSS_SELECTOR, "span.fluc-label")
            thumbnail_elements = driver.find_elements(By.CSS_SELECTOR, "div.thumb-wrapper.image div.thumb.lazy-image")
            channel_elements = driver.find_elements(By.CSS_SELECTOR, "td.channel a span.name")
            subscriber_elements = driver.find_elements(By.CSS_SELECTOR, "div.subs span.subs__count")

            log(f"ì´ {len(title_elements)}ê°œ í•­ëª©ì„ í˜ì´ì§€ì—ì„œ ë°œê²¬í•˜ì—¬ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
            
            for i in range(len(title_elements)):
                if len(all_collected_data) >= max_items:
                    log(f"ëª©í‘œ ìˆ˜ì§‘ëŸ‰({max_items}ê°œ)ì— ë„ë‹¬í•˜ì—¬ ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break 
                try:
                    title = title_elements[i].text.strip()
                    channel = channel_elements[i].text.strip() if i < len(channel_elements) else "N/A"
                    
                    item_hash = generate_hash(title, channel)
                    if item_hash in processed_hashes:
                        continue

                    views = view_elements[i].text.strip() if i < len(view_elements) else "N/A"
                    subscriber_count_text = subscriber_elements[i].text.strip() if i < len(subscriber_elements) else "êµ¬ë…ì ì •ë³´ ì—†ìŒ"
                    
                    subscriber_count_int = convert_subscriber_count_to_int(subscriber_count_text)
                    views_numeric = parse_views_to_int(views)

                    if not should_include_subscriber(subscriber_count_int):
                        continue

                    thumb_url = ""
                    if i < len(thumbnail_elements):
                        thumb_url_raw = thumbnail_elements[i].get_attribute("data-background-image")
                        if thumb_url_raw and thumb_url_raw.startswith("//"):
                            thumb_url = "https:" + thumb_url_raw

                    video_href = title_elements[i].get_attribute("href")
                    video_id = extract_video_id_from_href(video_href) or extract_video_id_from_thumbnail(thumb_url)
                    youtube_url = f"https://www.youtube.com/watch?v={video_id}" if video_id else ""

                    all_collected_data.append({
                        'Thumbnail': thumb_url,
                        'Title': title,
                        'Views': views,
                        'Views_numeric': views_numeric, # Add numeric views
                        'Channel': channel,
                        'Date': date_obj.strftime('%Y-%m-%d'),
                        'Subscribers': subscriber_count_text,
                        'Subscribers_numeric': subscriber_count_int, # Add numeric subscribers
                        'Hash': item_hash,
                        'YouTube URL': youtube_url
                    })
                    processed_hashes.add(item_hash)
                    
                    current_progress = int((len(all_collected_data) / max_items) * 100)
                    progress_bar.progress(min(current_progress, 100))

                except Exception as e:
                    log(f"âš ï¸ í•­ëª© {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    continue 

        new_df = pd.DataFrame(all_collected_data)
        if not new_df.empty:
            st.session_state.scraped_data = pd.concat([st.session_state.scraped_data, new_df]).drop_duplicates(subset=['Hash']).reset_index(drop=True)
        
        log(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(new_df)}ê°œ ì‹ ê·œ í•­ëª© ë°œê²¬, í˜„ì¬ ì´ {len(st.session_state.scraped_data)}ê°œ ê²°ê³¼.")

    except Exception as e:
        log(f"âŒ í¬ë¡¤ë§ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        st.session_state.is_scraping = False
        st.session_state.progress = 0


# --- Streamlit UI ---
st.title("ğŸ“Š Playboard Scraper")

# --- Sidebar for Inputs ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    with st.expander("ğŸ”‘ ë¡œê·¸ì¸ ë° API ì„¤ì •", expanded=True):
        email = st.text_input("Playboard ì´ë©”ì¼")
        password = st.text_input("Playboard ë¹„ë°€ë²ˆí˜¸", type="password")
        
        st.session_state['2captcha_api_key'] = st.text_input(
            "2Captcha API í‚¤ (ì„ íƒ ì‚¬í•­)", 
            value=st.session_state.get('2captcha_api_key', ''),
            type="password",
            help="ìº¡ì±  ìë™ í•´ê²°ì„ ìœ„í•´ 2Captcha API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ë¸Œë¼ìš°ì € íƒ­ì„ ë‹«ìœ¼ë©´ ì´ˆê¸°í™”ë©ë‹ˆë‹¤."
        )

        st.checkbox("í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰", value=True, key="run_headless", help="ì²´í¬ í•´ì œ ì‹œ í¬ë¡¬ ì°½ì´ ë‚˜íƒ€ë‚˜ë©°, ìº¡ì± ë¥¼ ì§ì ‘ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        if st.button("ë¡œê·¸ì¸", disabled=st.session_state.driver is not None):
            if email and password:
                with st.spinner("ë¡œê·¸ì¸ ì¤‘..."):
                    do_login(email, password)
                    st.rerun()
            else:
                st.warning("ì´ë©”ì¼ê³¼ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        st.info(st.session_state.login_status)
        if st.session_state.driver is not None:
            if st.button("ë¡œê·¸ì•„ì›ƒ/ë“œë¼ì´ë²„ ì¢…ë£Œ"):
                st.session_state.driver.quit()
                st.session_state.driver = None
                st.session_state.login_status = "Not logged in"
                st.rerun()

    with st.expander("ğŸ“ í¬ë¡¤ë§ ì„¤ì •", expanded=True):
        max_items_to_crawl = st.selectbox(
            "ìµœëŒ€ ìˆ˜ì§‘ ìˆœìœ„",
            (200, 500, 2500, 5000),
            index=3,
            key="max_items_selector"
        )
        
        date_input_text = st.text_area(
            "ë‚ ì§œ ì…ë ¥ (YYYYMMDD í˜•ì‹)",
            help="í•˜ë‚˜ì˜ ë‚ ì§œ (20240101), ì—¬ëŸ¬ ë‚ ì§œ (20240101, 20240102), ë˜ëŠ” ë²”ìœ„ (20240101-20240105)ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
            key="date_input"
        )

        country_option = st.radio(
            "êµ­ê°€ (ìˆí¼ ì „ìš©)",
            ('í•œêµ­', 'ë¯¸êµ­', 'ì¼ë³¸'),
            horizontal=True,
            key="country_selector"
        )

        if st.button("ì„¤ì • ì™„ë£Œ"):
            country_map = {
                'í•œêµ­': ('south-korea', 'í•œêµ­'),
                'ë¯¸êµ­': ('united-states', 'ë¯¸êµ­'),
                'ì¼ë³¸': ('japan', 'ì¼ë³¸')
            }
            parsed_dates = parse_dates(st.session_state.date_input)
            if parsed_dates:
                st.session_state.crawl_settings = {
                    "max_items": st.session_state.max_items_selector,
                    "dates": parsed_dates,
                    "country_code": country_map[st.session_state.country_selector][0],
                    "country_name": country_map[st.session_state.country_selector][1]
                }
                st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                log(f"ì„¤ì • ì €ì¥ë¨: {st.session_state.crawl_settings['max_items']}ê°œ, ë‚ ì§œ: {st.session_state.crawl_settings['dates']}, êµ­ê°€: {st.session_state.crawl_settings['country_name']}")
            else:
                st.error("ìœ íš¨í•œ ë‚ ì§œë¥¼ ì…ë ¥í•œ í›„ ì„¤ì •ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

    with st.expander("ğŸ“Š êµ¬ë…ì ìˆ˜ í•„í„°"):
        st.session_state.is_filter_applied = st.checkbox("í•„í„° ì ìš©í•˜ê¸°")
        
        for category, ranges in st.session_state.subscriber_filters.items():
            with st.container():
                st.write(f"**{category}**")
                cols = st.columns(3)
                i = 0
                for range_name in ranges:
                    st.session_state.subscriber_filters[category][range_name] = cols[i % 3].checkbox(range_name, value=st.session_state.subscriber_filters[category][range_name], key=f"filter_{category}_{range_name}")
                    i += 1
        
        st.write("**ì»¤ìŠ¤í…€ ë²”ìœ„**")
        st.session_state.use_custom_filter = st.checkbox("ì»¤ìŠ¤í…€ í•„í„° ì‚¬ìš©")
        col1, col2 = st.columns(2)
        custom_min_input = col1.text_input("ìµœì†Œ êµ¬ë…ì ìˆ˜", placeholder="ì˜ˆ: 12000")
        custom_max_input = col2.text_input("ìµœëŒ€ êµ¬ë…ì ìˆ˜", placeholder="ì˜ˆ: 55000")
        
        try:
            st.session_state.custom_min = int(custom_min_input.replace(',', '')) if custom_min_input else -1
            st.session_state.custom_max = int(custom_max_input.replace(',', '')) if custom_max_input else -1
        except ValueError:
            st.error("êµ¬ë…ì ìˆ˜ëŠ” ìˆ«ìë¡œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")


# --- Main Area ---
if st.button("ğŸš€ ìˆí¼ í¬ë¡¤ë§ ì‹œì‘", disabled=(st.session_state.is_scraping or st.session_state.driver is None or not st.session_state.crawl_settings['dates']), use_container_width=True):
    # st.session_state.scraped_data = pd.DataFrame() # ë” ì´ìƒ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
    settings = st.session_state.crawl_settings
    with st.spinner(f"{settings['max_items']}ê°œ ìˆí¼ í¬ë¡¤ë§ ì§„í–‰ ì¤‘..."):
        crawl(True, settings['dates'], settings['country_code'], settings['country_name'], settings['max_items'])
    st.rerun()

if st.button("ğŸ¬ ë¡±í¼ í¬ë¡¤ë§ ì‹œì‘", disabled=(st.session_state.is_scraping or st.session_state.driver is None or not st.session_state.crawl_settings['dates']), use_container_width=True):
    # st.session_state.scraped_data = pd.DataFrame() # ë” ì´ìƒ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
    settings = st.session_state.crawl_settings
    with st.spinner(f"{settings['max_items']}ê°œ ë¡±í¼ í¬ë¡¤ë§ ì§„í–‰ ì¤‘..."):
        crawl(False, settings['dates'], 'south-korea', 'í•œêµ­', settings['max_items'])
    st.rerun()

# --- Logging and Progress Display ---
st.text_area("Logs", "\n".join(st.session_state.log_messages), height=300, key="log_area_final")

# --- Results Display ---
tab1, tab2 = st.tabs(["ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼", "ğŸ“º ìœ íŠœë¸Œ ê²°ê³¼ (í˜„ì¬ ì„¸ì…˜)"])

with tab1:
    st.header("ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼")
    if not st.session_state.scraped_data.empty:
        # --- Sorting and Controls ---
        sort_option = st.selectbox(
            "ê²°ê³¼ ì •ë ¬",
            options=["ê¸°ë³¸", "ì±„ë„ë³„ ì •ë ¬", "ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ", "ì¡°íšŒìˆ˜ ë‚®ì€ ìˆœ", "êµ¬ë…ì ë§ì€ ìˆœ", "êµ¬ë…ì ì ì€ ìˆœ"],
            key="sort_scraped"
        )
        if st.button("í¬ë¡¤ë§ ê²°ê³¼ ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.scraped_data = pd.DataFrame()
            st.rerun()

        # --- Data Sorting Logic ---
        display_df = st.session_state.scraped_data.copy()
        if sort_option == "ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ": display_df = display_df.sort_values(by="Views_numeric", ascending=False)
        elif sort_option == "ì¡°íšŒìˆ˜ ë‚®ì€ ìˆœ": display_df = display_df.sort_values(by="Views_numeric", ascending=True)
        elif sort_option == "êµ¬ë…ì ë§ì€ ìˆœ": display_df = display_df.sort_values(by="Subscribers_numeric", ascending=False)
        elif sort_option == "êµ¬ë…ì ì ì€ ìˆœ": display_df = display_df.sort_values(by="Subscribers_numeric", ascending=True)
        elif sort_option == "ì±„ë„ë³„ ì •ë ¬": display_df = display_df.sort_values(by=['Channel', 'Views_numeric'], ascending=[True, False])
        
        display_df.insert(0, "ì„ íƒ", False)

        edited_df = st.data_editor(
            display_df,
            column_config={
                "ì„ íƒ": st.column_config.CheckboxColumn(required=True),
                "Thumbnail": st.column_config.ImageColumn("ì¸ë„¤ì¼", help="ë™ì˜ìƒ ì¸ë„¤ì¼"),
                "Views_numeric": None, 
                "Subscribers_numeric": None,
                "Hash": None # Hash ì—´ ìˆ¨ê¸°ê¸°
            }, hide_index=True, key="results_editor"
        )
        
        selected_rows = edited_df[edited_df["ì„ íƒ"]]
        if not selected_rows.empty and st.button(f"{len(selected_rows)}ê°œ í•­ëª© ìœ íŠœë¸Œ ê²°ê³¼ì— ì¶”ê°€", use_container_width=True):
            items_to_add = selected_rows.drop(columns=['ì„ íƒ'])
            updated_cart = pd.concat([st.session_state.shopping_cart, items_to_add]).drop_duplicates(subset=['Hash']).reset_index(drop=True)
            st.session_state.shopping_cart = updated_cart
            # save_app_data() # íŒŒì¼ ì €ì¥ ë¡œì§ ì‚­ì œ
            st.success(f"{len(items_to_add)}ê°œ í•­ëª©ì„ ìœ íŠœë¸Œ ê²°ê³¼ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤!")
            time.sleep(1); st.rerun()
    else:
        st.info("í¬ë¡¤ë§ì„ ì‹œì‘í•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

with tab2:
    st.header("ğŸ“º ìœ íŠœë¸Œ ê²°ê³¼ (í˜„ì¬ ì„¸ì…˜)")
    if not st.session_state.shopping_cart.empty:
        sort_option_cart = st.selectbox(
            "ìœ íŠœë¸Œ ê²°ê³¼ ì •ë ¬",
            options=["ê¸°ë³¸", "ì±„ë„ë³„ ì •ë ¬", "ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ", "ì¡°íšŒìˆ˜ ë‚®ì€ ìˆœ", "êµ¬ë…ì ë§ì€ ìˆœ", "êµ¬ë…ì ì ì€ ìˆœ"],
            key="sort_cart"
        )
        cart_df_with_selector = st.session_state.shopping_cart.copy()
        if sort_option_cart == "ì¡°íšŒìˆ˜ ë†’ì€ ìˆœ": cart_df_with_selector = cart_df_with_selector.sort_values(by="Views_numeric", ascending=False)
        elif sort_option_cart == "ì¡°íšŒìˆ˜ ë‚®ì€ ìˆœ": cart_df_with_selector = cart_df_with_selector.sort_values(by="Views_numeric", ascending=True)
        elif sort_option_cart == "êµ¬ë…ì ë§ì€ ìˆœ": cart_df_with_selector = cart_df_with_selector.sort_values(by="Subscribers_numeric", ascending=False)
        elif sort_option_cart == "êµ¬ë…ì ì ì€ ìˆœ": cart_df_with_selector = cart_df_with_selector.sort_values(by="Subscribers_numeric", ascending=True)
        elif sort_option_cart == "ì±„ë„ë³„ ì •ë ¬": cart_df_with_selector = cart_df_with_selector.sort_values(by=['Channel', 'Views_numeric'], ascending=[True, False])

        cart_df_with_selector.insert(0, "ì„ íƒ", False)
        
        st.info("ì´ê³³ì˜ ë°ì´í„°ëŠ” ì•±ì„ ì¢…ë£Œí•´ë„ ìœ ì§€ë©ë‹ˆë‹¤. ê·¸ë£¹ìœ¼ë¡œ ë§Œë“¤ê±°ë‚˜ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        edited_cart_df = st.data_editor(
            cart_df_with_selector,
            column_config={
                "ì„ íƒ": st.column_config.CheckboxColumn(required=True), "Thumbnail": st.column_config.ImageColumn("ì¸ë„¤ì¼"),
                "Views_numeric": None, "Subscribers_numeric": None,
                "Hash": None # Hash ì—´ ìˆ¨ê¸°ê¸°
            }, hide_index=True, key="cart_editor"
        )
        selected_cart_rows = edited_cart_df[edited_cart_df["ì„ íƒ"]]

        st.markdown("---")
        st.subheader("ì„ íƒí•œ í•­ëª©ìœ¼ë¡œ ì‘ì—…í•˜ê¸°")
        
        new_group_name = st.text_input("ìƒˆ ê·¸ë£¹ ì´ë¦„", placeholder="ì˜ˆ: 7ì›” 1ì£¼ì°¨ ìˆí¼")
        if st.button("ê·¸ë£¹ ë§Œë“¤ê¸°", disabled=selected_cart_rows.empty or not new_group_name, use_container_width=True):
            if new_group_name in st.session_state.custom_groups:
                st.error(f"'{new_group_name}' ê·¸ë£¹ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            else:
                st.session_state.custom_groups[new_group_name] = selected_cart_rows.drop(columns=['ì„ íƒ'])
                # save_app_data() # íŒŒì¼ ì €ì¥ ë¡œì§ ì‚­ì œ
                st.success(f"'{new_group_name}' ê·¸ë£¹ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.")
                time.sleep(1); st.rerun()

        st.markdown("---") # Visual separator

        csv_cart = convert_df_to_csv(st.session_state.shopping_cart.drop(columns=['Views_numeric', 'Subscribers_numeric'], errors='ignore'))
        st.download_button("ğŸ’¾ CSV ë‹¤ìš´ë¡œë“œ (ì „ì²´)", csv_cart, f"youtube_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", "text/csv", use_container_width=True)
        
        pdf_cart = convert_df_to_pdf(st.session_state.shopping_cart.drop(columns=['Views_numeric', 'Subscribers_numeric', 'Thumbnail', 'YouTube URL', 'Hash'], errors='ignore'))
        st.download_button("ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ (ì „ì²´)", pdf_cart, f"youtube_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf", "application/pdf", use_container_width=True)
        
        if st.button("ì „ì²´ ê²°ê³¼ ë¹„ìš°ê¸°", use_container_width=True):
            st.session_state.shopping_cart = pd.DataFrame()
            # save_app_data() # íŒŒì¼ ì €ì¥ ë¡œì§ ì‚­ì œ
            st.rerun()

    else:
        st.info("ê²°ê³¼ í…Œì´ë¸”ì—ì„œ í•­ëª©ì„ ì„ íƒí•˜ì—¬ 'ìœ íŠœë¸Œ ê²°ê³¼'ì— ì¶”ê°€í•˜ì„¸ìš”.")

    st.markdown("---")
    st.header("ğŸ“‚ ì €ì¥ëœ ê·¸ë£¹ (í˜„ì¬ ì„¸ì…˜)")
    if not st.session_state.custom_groups:
        st.info("ë§Œë“¤ì–´ì§„ ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for group_name in list(st.session_state.custom_groups.keys()):
            with st.expander(f"**{group_name}** ({len(st.session_state.custom_groups[group_name])}ê°œ í•­ëª©)"):
                group_df = st.session_state.custom_groups[group_name]
                st.dataframe(group_df, column_config={"Thumbnail": st.column_config.ImageColumn("ì¸ë„¤ì¼"), "Views_numeric": None, "Subscribers_numeric": None, "Hash": None}, hide_index=True)
                if st.button(f"'{group_name}' ê·¸ë£¹ ì‚­ì œ", key=f"delete_{group_name}", use_container_width=True):
                    del st.session_state.custom_groups[group_name]
                    # save_app_data() # íŒŒì¼ ì €ì¥ ë¡œì§ ì‚­ì œ
                    st.rerun()
